{"ast":null,"code":"/* jshint -W086: true */\n// +----------------------------------------------------------------------+\n// | murmurHash3js.js v3.0.1 // https://github.com/pid/murmurHash3js\n// | A javascript implementation of MurmurHash3's x86 hashing algorithms. |\n// |----------------------------------------------------------------------|\n// | Copyright (c) 2012-2015 Karan Lyons                                       |\n// | https://github.com/karanlyons/murmurHash3.js/blob/c1778f75792abef7bdd74bc85d2d4e1a3d25cfe9/murmurHash3.js |\n// | Freely distributable under the MIT license.                          |\n// +----------------------------------------------------------------------+\n;\n\n(function (root, undefined) {\n  'use strict'; // Create a local object that'll be exported or referenced globally.\n\n  var library = {\n    'version': '3.0.0',\n    'x86': {},\n    'x64': {},\n    'inputValidation': true\n  }; // PRIVATE FUNCTIONS\n  // -----------------\n\n  function _validBytes(bytes) {\n    // check the input is an array or a typed array\n    if (!Array.isArray(bytes) && !ArrayBuffer.isView(bytes)) {\n      return false;\n    } // check all bytes are actually bytes\n\n\n    for (var i = 0; i < bytes.length; i++) {\n      if (!Number.isInteger(bytes[i]) || bytes[i] < 0 || bytes[i] > 255) {\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n  function _x86Multiply(m, n) {\n    //\n    // Given two 32bit ints, returns the two multiplied together as a\n    // 32bit int.\n    //\n    return (m & 0xffff) * n + (((m >>> 16) * n & 0xffff) << 16);\n  }\n\n  function _x86Rotl(m, n) {\n    //\n    // Given a 32bit int and an int representing a number of bit positions,\n    // returns the 32bit int rotated left by that number of positions.\n    //\n    return m << n | m >>> 32 - n;\n  }\n\n  function _x86Fmix(h) {\n    //\n    // Given a block, returns murmurHash3's final x86 mix of that block.\n    //\n    h ^= h >>> 16;\n    h = _x86Multiply(h, 0x85ebca6b);\n    h ^= h >>> 13;\n    h = _x86Multiply(h, 0xc2b2ae35);\n    h ^= h >>> 16;\n    return h;\n  }\n\n  function _x64Add(m, n) {\n    //\n    // Given two 64bit ints (as an array of two 32bit ints) returns the two\n    // added together as a 64bit int (as an array of two 32bit ints).\n    //\n    m = [m[0] >>> 16, m[0] & 0xffff, m[1] >>> 16, m[1] & 0xffff];\n    n = [n[0] >>> 16, n[0] & 0xffff, n[1] >>> 16, n[1] & 0xffff];\n    var o = [0, 0, 0, 0];\n    o[3] += m[3] + n[3];\n    o[2] += o[3] >>> 16;\n    o[3] &= 0xffff;\n    o[2] += m[2] + n[2];\n    o[1] += o[2] >>> 16;\n    o[2] &= 0xffff;\n    o[1] += m[1] + n[1];\n    o[0] += o[1] >>> 16;\n    o[1] &= 0xffff;\n    o[0] += m[0] + n[0];\n    o[0] &= 0xffff;\n    return [o[0] << 16 | o[1], o[2] << 16 | o[3]];\n  }\n\n  function _x64Multiply(m, n) {\n    //\n    // Given two 64bit ints (as an array of two 32bit ints) returns the two\n    // multiplied together as a 64bit int (as an array of two 32bit ints).\n    //\n    m = [m[0] >>> 16, m[0] & 0xffff, m[1] >>> 16, m[1] & 0xffff];\n    n = [n[0] >>> 16, n[0] & 0xffff, n[1] >>> 16, n[1] & 0xffff];\n    var o = [0, 0, 0, 0];\n    o[3] += m[3] * n[3];\n    o[2] += o[3] >>> 16;\n    o[3] &= 0xffff;\n    o[2] += m[2] * n[3];\n    o[1] += o[2] >>> 16;\n    o[2] &= 0xffff;\n    o[2] += m[3] * n[2];\n    o[1] += o[2] >>> 16;\n    o[2] &= 0xffff;\n    o[1] += m[1] * n[3];\n    o[0] += o[1] >>> 16;\n    o[1] &= 0xffff;\n    o[1] += m[2] * n[2];\n    o[0] += o[1] >>> 16;\n    o[1] &= 0xffff;\n    o[1] += m[3] * n[1];\n    o[0] += o[1] >>> 16;\n    o[1] &= 0xffff;\n    o[0] += m[0] * n[3] + m[1] * n[2] + m[2] * n[1] + m[3] * n[0];\n    o[0] &= 0xffff;\n    return [o[0] << 16 | o[1], o[2] << 16 | o[3]];\n  }\n\n  function _x64Rotl(m, n) {\n    //\n    // Given a 64bit int (as an array of two 32bit ints) and an int\n    // representing a number of bit positions, returns the 64bit int (as an\n    // array of two 32bit ints) rotated left by that number of positions.\n    //\n    n %= 64;\n\n    if (n === 32) {\n      return [m[1], m[0]];\n    } else if (n < 32) {\n      return [m[0] << n | m[1] >>> 32 - n, m[1] << n | m[0] >>> 32 - n];\n    } else {\n      n -= 32;\n      return [m[1] << n | m[0] >>> 32 - n, m[0] << n | m[1] >>> 32 - n];\n    }\n  }\n\n  function _x64LeftShift(m, n) {\n    //\n    // Given a 64bit int (as an array of two 32bit ints) and an int\n    // representing a number of bit positions, returns the 64bit int (as an\n    // array of two 32bit ints) shifted left by that number of positions.\n    //\n    n %= 64;\n\n    if (n === 0) {\n      return m;\n    } else if (n < 32) {\n      return [m[0] << n | m[1] >>> 32 - n, m[1] << n];\n    } else {\n      return [m[1] << n - 32, 0];\n    }\n  }\n\n  function _x64Xor(m, n) {\n    //\n    // Given two 64bit ints (as an array of two 32bit ints) returns the two\n    // xored together as a 64bit int (as an array of two 32bit ints).\n    //\n    return [m[0] ^ n[0], m[1] ^ n[1]];\n  }\n\n  function _x64Fmix(h) {\n    //\n    // Given a block, returns murmurHash3's final x64 mix of that block.\n    // (`[0, h[0] >>> 1]` is a 33 bit unsigned right shift. This is the\n    // only place where we need to right shift 64bit ints.)\n    //\n    h = _x64Xor(h, [0, h[0] >>> 1]);\n    h = _x64Multiply(h, [0xff51afd7, 0xed558ccd]);\n    h = _x64Xor(h, [0, h[0] >>> 1]);\n    h = _x64Multiply(h, [0xc4ceb9fe, 0x1a85ec53]);\n    h = _x64Xor(h, [0, h[0] >>> 1]);\n    return h;\n  } // PUBLIC FUNCTIONS\n  // ----------------\n\n\n  library.x86.hash32 = function (bytes, seed) {\n    //\n    // Given a string and an optional seed as an int, returns a 32 bit hash\n    // using the x86 flavor of MurmurHash3, as an unsigned int.\n    //\n    if (library.inputValidation && !_validBytes(bytes)) {\n      return undefined;\n    }\n\n    seed = seed || 0;\n    var remainder = bytes.length % 4;\n    var blocks = bytes.length - remainder;\n    var h1 = seed;\n    var k1 = 0;\n    var c1 = 0xcc9e2d51;\n    var c2 = 0x1b873593;\n\n    for (var i = 0; i < blocks; i = i + 4) {\n      k1 = bytes[i] | bytes[i + 1] << 8 | bytes[i + 2] << 16 | bytes[i + 3] << 24;\n      k1 = _x86Multiply(k1, c1);\n      k1 = _x86Rotl(k1, 15);\n      k1 = _x86Multiply(k1, c2);\n      h1 ^= k1;\n      h1 = _x86Rotl(h1, 13);\n      h1 = _x86Multiply(h1, 5) + 0xe6546b64;\n    }\n\n    k1 = 0;\n\n    switch (remainder) {\n      case 3:\n        k1 ^= bytes[i + 2] << 16;\n\n      case 2:\n        k1 ^= bytes[i + 1] << 8;\n\n      case 1:\n        k1 ^= bytes[i];\n        k1 = _x86Multiply(k1, c1);\n        k1 = _x86Rotl(k1, 15);\n        k1 = _x86Multiply(k1, c2);\n        h1 ^= k1;\n    }\n\n    h1 ^= bytes.length;\n    h1 = _x86Fmix(h1);\n    return h1 >>> 0;\n  };\n\n  library.x86.hash128 = function (bytes, seed) {\n    //\n    // Given a string and an optional seed as an int, returns a 128 bit\n    // hash using the x86 flavor of MurmurHash3, as an unsigned hex.\n    //\n    if (library.inputValidation && !_validBytes(bytes)) {\n      return undefined;\n    }\n\n    seed = seed || 0;\n    var remainder = bytes.length % 16;\n    var blocks = bytes.length - remainder;\n    var h1 = seed;\n    var h2 = seed;\n    var h3 = seed;\n    var h4 = seed;\n    var k1 = 0;\n    var k2 = 0;\n    var k3 = 0;\n    var k4 = 0;\n    var c1 = 0x239b961b;\n    var c2 = 0xab0e9789;\n    var c3 = 0x38b34ae5;\n    var c4 = 0xa1e38b93;\n\n    for (var i = 0; i < blocks; i = i + 16) {\n      k1 = bytes[i] | bytes[i + 1] << 8 | bytes[i + 2] << 16 | bytes[i + 3] << 24;\n      k2 = bytes[i + 4] | bytes[i + 5] << 8 | bytes[i + 6] << 16 | bytes[i + 7] << 24;\n      k3 = bytes[i + 8] | bytes[i + 9] << 8 | bytes[i + 10] << 16 | bytes[i + 11] << 24;\n      k4 = bytes[i + 12] | bytes[i + 13] << 8 | bytes[i + 14] << 16 | bytes[i + 15] << 24;\n      k1 = _x86Multiply(k1, c1);\n      k1 = _x86Rotl(k1, 15);\n      k1 = _x86Multiply(k1, c2);\n      h1 ^= k1;\n      h1 = _x86Rotl(h1, 19);\n      h1 += h2;\n      h1 = _x86Multiply(h1, 5) + 0x561ccd1b;\n      k2 = _x86Multiply(k2, c2);\n      k2 = _x86Rotl(k2, 16);\n      k2 = _x86Multiply(k2, c3);\n      h2 ^= k2;\n      h2 = _x86Rotl(h2, 17);\n      h2 += h3;\n      h2 = _x86Multiply(h2, 5) + 0x0bcaa747;\n      k3 = _x86Multiply(k3, c3);\n      k3 = _x86Rotl(k3, 17);\n      k3 = _x86Multiply(k3, c4);\n      h3 ^= k3;\n      h3 = _x86Rotl(h3, 15);\n      h3 += h4;\n      h3 = _x86Multiply(h3, 5) + 0x96cd1c35;\n      k4 = _x86Multiply(k4, c4);\n      k4 = _x86Rotl(k4, 18);\n      k4 = _x86Multiply(k4, c1);\n      h4 ^= k4;\n      h4 = _x86Rotl(h4, 13);\n      h4 += h1;\n      h4 = _x86Multiply(h4, 5) + 0x32ac3b17;\n    }\n\n    k1 = 0;\n    k2 = 0;\n    k3 = 0;\n    k4 = 0;\n\n    switch (remainder) {\n      case 15:\n        k4 ^= bytes[i + 14] << 16;\n\n      case 14:\n        k4 ^= bytes[i + 13] << 8;\n\n      case 13:\n        k4 ^= bytes[i + 12];\n        k4 = _x86Multiply(k4, c4);\n        k4 = _x86Rotl(k4, 18);\n        k4 = _x86Multiply(k4, c1);\n        h4 ^= k4;\n\n      case 12:\n        k3 ^= bytes[i + 11] << 24;\n\n      case 11:\n        k3 ^= bytes[i + 10] << 16;\n\n      case 10:\n        k3 ^= bytes[i + 9] << 8;\n\n      case 9:\n        k3 ^= bytes[i + 8];\n        k3 = _x86Multiply(k3, c3);\n        k3 = _x86Rotl(k3, 17);\n        k3 = _x86Multiply(k3, c4);\n        h3 ^= k3;\n\n      case 8:\n        k2 ^= bytes[i + 7] << 24;\n\n      case 7:\n        k2 ^= bytes[i + 6] << 16;\n\n      case 6:\n        k2 ^= bytes[i + 5] << 8;\n\n      case 5:\n        k2 ^= bytes[i + 4];\n        k2 = _x86Multiply(k2, c2);\n        k2 = _x86Rotl(k2, 16);\n        k2 = _x86Multiply(k2, c3);\n        h2 ^= k2;\n\n      case 4:\n        k1 ^= bytes[i + 3] << 24;\n\n      case 3:\n        k1 ^= bytes[i + 2] << 16;\n\n      case 2:\n        k1 ^= bytes[i + 1] << 8;\n\n      case 1:\n        k1 ^= bytes[i];\n        k1 = _x86Multiply(k1, c1);\n        k1 = _x86Rotl(k1, 15);\n        k1 = _x86Multiply(k1, c2);\n        h1 ^= k1;\n    }\n\n    h1 ^= bytes.length;\n    h2 ^= bytes.length;\n    h3 ^= bytes.length;\n    h4 ^= bytes.length;\n    h1 += h2;\n    h1 += h3;\n    h1 += h4;\n    h2 += h1;\n    h3 += h1;\n    h4 += h1;\n    h1 = _x86Fmix(h1);\n    h2 = _x86Fmix(h2);\n    h3 = _x86Fmix(h3);\n    h4 = _x86Fmix(h4);\n    h1 += h2;\n    h1 += h3;\n    h1 += h4;\n    h2 += h1;\n    h3 += h1;\n    h4 += h1;\n    return (\"00000000\" + (h1 >>> 0).toString(16)).slice(-8) + (\"00000000\" + (h2 >>> 0).toString(16)).slice(-8) + (\"00000000\" + (h3 >>> 0).toString(16)).slice(-8) + (\"00000000\" + (h4 >>> 0).toString(16)).slice(-8);\n  };\n\n  library.x64.hash128 = function (bytes, seed) {\n    //\n    // Given a string and an optional seed as an int, returns a 128 bit\n    // hash using the x64 flavor of MurmurHash3, as an unsigned hex.\n    //\n    if (library.inputValidation && !_validBytes(bytes)) {\n      return undefined;\n    }\n\n    seed = seed || 0;\n    var remainder = bytes.length % 16;\n    var blocks = bytes.length - remainder;\n    var h1 = [0, seed];\n    var h2 = [0, seed];\n    var k1 = [0, 0];\n    var k2 = [0, 0];\n    var c1 = [0x87c37b91, 0x114253d5];\n    var c2 = [0x4cf5ad43, 0x2745937f];\n\n    for (var i = 0; i < blocks; i = i + 16) {\n      k1 = [bytes[i + 4] | bytes[i + 5] << 8 | bytes[i + 6] << 16 | bytes[i + 7] << 24, bytes[i] | bytes[i + 1] << 8 | bytes[i + 2] << 16 | bytes[i + 3] << 24];\n      k2 = [bytes[i + 12] | bytes[i + 13] << 8 | bytes[i + 14] << 16 | bytes[i + 15] << 24, bytes[i + 8] | bytes[i + 9] << 8 | bytes[i + 10] << 16 | bytes[i + 11] << 24];\n      k1 = _x64Multiply(k1, c1);\n      k1 = _x64Rotl(k1, 31);\n      k1 = _x64Multiply(k1, c2);\n      h1 = _x64Xor(h1, k1);\n      h1 = _x64Rotl(h1, 27);\n      h1 = _x64Add(h1, h2);\n      h1 = _x64Add(_x64Multiply(h1, [0, 5]), [0, 0x52dce729]);\n      k2 = _x64Multiply(k2, c2);\n      k2 = _x64Rotl(k2, 33);\n      k2 = _x64Multiply(k2, c1);\n      h2 = _x64Xor(h2, k2);\n      h2 = _x64Rotl(h2, 31);\n      h2 = _x64Add(h2, h1);\n      h2 = _x64Add(_x64Multiply(h2, [0, 5]), [0, 0x38495ab5]);\n    }\n\n    k1 = [0, 0];\n    k2 = [0, 0];\n\n    switch (remainder) {\n      case 15:\n        k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 14]], 48));\n\n      case 14:\n        k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 13]], 40));\n\n      case 13:\n        k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 12]], 32));\n\n      case 12:\n        k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 11]], 24));\n\n      case 11:\n        k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 10]], 16));\n\n      case 10:\n        k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 9]], 8));\n\n      case 9:\n        k2 = _x64Xor(k2, [0, bytes[i + 8]]);\n        k2 = _x64Multiply(k2, c2);\n        k2 = _x64Rotl(k2, 33);\n        k2 = _x64Multiply(k2, c1);\n        h2 = _x64Xor(h2, k2);\n\n      case 8:\n        k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 7]], 56));\n\n      case 7:\n        k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 6]], 48));\n\n      case 6:\n        k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 5]], 40));\n\n      case 5:\n        k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 4]], 32));\n\n      case 4:\n        k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 3]], 24));\n\n      case 3:\n        k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 2]], 16));\n\n      case 2:\n        k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 1]], 8));\n\n      case 1:\n        k1 = _x64Xor(k1, [0, bytes[i]]);\n        k1 = _x64Multiply(k1, c1);\n        k1 = _x64Rotl(k1, 31);\n        k1 = _x64Multiply(k1, c2);\n        h1 = _x64Xor(h1, k1);\n    }\n\n    h1 = _x64Xor(h1, [0, bytes.length]);\n    h2 = _x64Xor(h2, [0, bytes.length]);\n    h1 = _x64Add(h1, h2);\n    h2 = _x64Add(h2, h1);\n    h1 = _x64Fmix(h1);\n    h2 = _x64Fmix(h2);\n    h1 = _x64Add(h1, h2);\n    h2 = _x64Add(h2, h1);\n    return (\"00000000\" + (h1[0] >>> 0).toString(16)).slice(-8) + (\"00000000\" + (h1[1] >>> 0).toString(16)).slice(-8) + (\"00000000\" + (h2[0] >>> 0).toString(16)).slice(-8) + (\"00000000\" + (h2[1] >>> 0).toString(16)).slice(-8);\n  }; // INITIALIZATION\n  // --------------\n  // Export murmurHash3 for CommonJS, either as an AMD module or just as part\n  // of the global object.\n\n\n  if (typeof exports !== 'undefined') {\n    if (typeof module !== 'undefined' && module.exports) {\n      exports = module.exports = library;\n    }\n\n    exports.murmurHash3 = library;\n  } else if (typeof define === 'function' && define.amd) {\n    define([], function () {\n      return library;\n    });\n  } else {\n    // Use murmurHash3.noConflict to restore `murmurHash3` back to its\n    // original value. Returns a reference to the library object, to allow\n    // it to be used under a different name.\n    library._murmurHash3 = root.murmurHash3;\n\n    library.noConflict = function () {\n      root.murmurHash3 = library._murmurHash3;\n      library._murmurHash3 = undefined;\n      library.noConflict = undefined;\n      return library;\n    };\n\n    root.murmurHash3 = library;\n  }\n})(this);","map":{"version":3,"sources":["/home/ranju/location/meDossier/frontend/node_modules/murmurhash3js-revisited/lib/murmurHash3js.js"],"names":["root","undefined","library","_validBytes","bytes","Array","isArray","ArrayBuffer","isView","i","length","Number","isInteger","_x86Multiply","m","n","_x86Rotl","_x86Fmix","h","_x64Add","o","_x64Multiply","_x64Rotl","_x64LeftShift","_x64Xor","_x64Fmix","x86","hash32","seed","inputValidation","remainder","blocks","h1","k1","c1","c2","hash128","h2","h3","h4","k2","k3","k4","c3","c4","toString","slice","x64","exports","module","murmurHash3","define","amd","_murmurHash3","noConflict"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAAC,CAAC,UAAUA,IAAV,EAAgBC,SAAhB,EAA2B;AACzB,eADyB,CAGzB;;AACA,MAAIC,OAAO,GAAG;AACV,eAAW,OADD;AAEV,WAAO,EAFG;AAGV,WAAO,EAHG;AAIV,uBAAmB;AAJT,GAAd,CAJyB,CAWzB;AACA;;AAEA,WAASC,WAAT,CAAqBC,KAArB,EAA4B;AACxB;AACA,QAAI,CAACC,KAAK,CAACC,OAAN,CAAcF,KAAd,CAAD,IAAyB,CAACG,WAAW,CAACC,MAAZ,CAAmBJ,KAAnB,CAA9B,EAAyD;AACrD,aAAO,KAAP;AACH,KAJuB,CAMxB;;;AACA,SAAK,IAAIK,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGL,KAAK,CAACM,MAA1B,EAAkCD,CAAC,EAAnC,EAAuC;AACnC,UAAI,CAACE,MAAM,CAACC,SAAP,CAAiBR,KAAK,CAACK,CAAD,CAAtB,CAAD,IAA+BL,KAAK,CAACK,CAAD,CAAL,GAAW,CAA1C,IAA+CL,KAAK,CAACK,CAAD,CAAL,GAAW,GAA9D,EAAmE;AAC/D,eAAO,KAAP;AACH;AACJ;;AACD,WAAO,IAAP;AACH;;AAED,WAASI,YAAT,CAAsBC,CAAtB,EAAyBC,CAAzB,EAA4B;AACxB;AACA;AACA;AACA;AAEA,WAAQ,CAACD,CAAC,GAAG,MAAL,IAAeC,CAAhB,IAAsB,CAAE,CAACD,CAAC,KAAK,EAAP,IAAaC,CAAd,GAAmB,MAApB,KAA+B,EAArD,CAAP;AACH;;AAED,WAASC,QAAT,CAAkBF,CAAlB,EAAqBC,CAArB,EAAwB;AACpB;AACA;AACA;AACA;AAEA,WAAQD,CAAC,IAAIC,CAAN,GAAYD,CAAC,KAAM,KAAKC,CAA/B;AACH;;AAED,WAASE,QAAT,CAAkBC,CAAlB,EAAqB;AACjB;AACA;AACA;AAEAA,IAAAA,CAAC,IAAIA,CAAC,KAAK,EAAX;AACAA,IAAAA,CAAC,GAAGL,YAAY,CAACK,CAAD,EAAI,UAAJ,CAAhB;AACAA,IAAAA,CAAC,IAAIA,CAAC,KAAK,EAAX;AACAA,IAAAA,CAAC,GAAGL,YAAY,CAACK,CAAD,EAAI,UAAJ,CAAhB;AACAA,IAAAA,CAAC,IAAIA,CAAC,KAAK,EAAX;AAEA,WAAOA,CAAP;AACH;;AAED,WAASC,OAAT,CAAiBL,CAAjB,EAAoBC,CAApB,EAAuB;AACnB;AACA;AACA;AACA;AAEAD,IAAAA,CAAC,GAAG,CAACA,CAAC,CAAC,CAAD,CAAD,KAAS,EAAV,EAAcA,CAAC,CAAC,CAAD,CAAD,GAAO,MAArB,EAA6BA,CAAC,CAAC,CAAD,CAAD,KAAS,EAAtC,EAA0CA,CAAC,CAAC,CAAD,CAAD,GAAO,MAAjD,CAAJ;AACAC,IAAAA,CAAC,GAAG,CAACA,CAAC,CAAC,CAAD,CAAD,KAAS,EAAV,EAAcA,CAAC,CAAC,CAAD,CAAD,GAAO,MAArB,EAA6BA,CAAC,CAAC,CAAD,CAAD,KAAS,EAAtC,EAA0CA,CAAC,CAAC,CAAD,CAAD,GAAO,MAAjD,CAAJ;AACA,QAAIK,CAAC,GAAG,CAAC,CAAD,EAAI,CAAJ,EAAO,CAAP,EAAU,CAAV,CAAR;AAEAA,IAAAA,CAAC,CAAC,CAAD,CAAD,IAAQN,CAAC,CAAC,CAAD,CAAD,GAAOC,CAAC,CAAC,CAAD,CAAhB;AACAK,IAAAA,CAAC,CAAC,CAAD,CAAD,IAAQA,CAAC,CAAC,CAAD,CAAD,KAAS,EAAjB;AACAA,IAAAA,CAAC,CAAC,CAAD,CAAD,IAAQ,MAAR;AAEAA,IAAAA,CAAC,CAAC,CAAD,CAAD,IAAQN,CAAC,CAAC,CAAD,CAAD,GAAOC,CAAC,CAAC,CAAD,CAAhB;AACAK,IAAAA,CAAC,CAAC,CAAD,CAAD,IAAQA,CAAC,CAAC,CAAD,CAAD,KAAS,EAAjB;AACAA,IAAAA,CAAC,CAAC,CAAD,CAAD,IAAQ,MAAR;AAEAA,IAAAA,CAAC,CAAC,CAAD,CAAD,IAAQN,CAAC,CAAC,CAAD,CAAD,GAAOC,CAAC,CAAC,CAAD,CAAhB;AACAK,IAAAA,CAAC,CAAC,CAAD,CAAD,IAAQA,CAAC,CAAC,CAAD,CAAD,KAAS,EAAjB;AACAA,IAAAA,CAAC,CAAC,CAAD,CAAD,IAAQ,MAAR;AAEAA,IAAAA,CAAC,CAAC,CAAD,CAAD,IAAQN,CAAC,CAAC,CAAD,CAAD,GAAOC,CAAC,CAAC,CAAD,CAAhB;AACAK,IAAAA,CAAC,CAAC,CAAD,CAAD,IAAQ,MAAR;AAEA,WAAO,CAAEA,CAAC,CAAC,CAAD,CAAD,IAAQ,EAAT,GAAeA,CAAC,CAAC,CAAD,CAAjB,EAAuBA,CAAC,CAAC,CAAD,CAAD,IAAQ,EAAT,GAAeA,CAAC,CAAC,CAAD,CAAtC,CAAP;AACH;;AAED,WAASC,YAAT,CAAsBP,CAAtB,EAAyBC,CAAzB,EAA4B;AACxB;AACA;AACA;AACA;AAEAD,IAAAA,CAAC,GAAG,CAACA,CAAC,CAAC,CAAD,CAAD,KAAS,EAAV,EAAcA,CAAC,CAAC,CAAD,CAAD,GAAO,MAArB,EAA6BA,CAAC,CAAC,CAAD,CAAD,KAAS,EAAtC,EAA0CA,CAAC,CAAC,CAAD,CAAD,GAAO,MAAjD,CAAJ;AACAC,IAAAA,CAAC,GAAG,CAACA,CAAC,CAAC,CAAD,CAAD,KAAS,EAAV,EAAcA,CAAC,CAAC,CAAD,CAAD,GAAO,MAArB,EAA6BA,CAAC,CAAC,CAAD,CAAD,KAAS,EAAtC,EAA0CA,CAAC,CAAC,CAAD,CAAD,GAAO,MAAjD,CAAJ;AACA,QAAIK,CAAC,GAAG,CAAC,CAAD,EAAI,CAAJ,EAAO,CAAP,EAAU,CAAV,CAAR;AAEAA,IAAAA,CAAC,CAAC,CAAD,CAAD,IAAQN,CAAC,CAAC,CAAD,CAAD,GAAOC,CAAC,CAAC,CAAD,CAAhB;AACAK,IAAAA,CAAC,CAAC,CAAD,CAAD,IAAQA,CAAC,CAAC,CAAD,CAAD,KAAS,EAAjB;AACAA,IAAAA,CAAC,CAAC,CAAD,CAAD,IAAQ,MAAR;AAEAA,IAAAA,CAAC,CAAC,CAAD,CAAD,IAAQN,CAAC,CAAC,CAAD,CAAD,GAAOC,CAAC,CAAC,CAAD,CAAhB;AACAK,IAAAA,CAAC,CAAC,CAAD,CAAD,IAAQA,CAAC,CAAC,CAAD,CAAD,KAAS,EAAjB;AACAA,IAAAA,CAAC,CAAC,CAAD,CAAD,IAAQ,MAAR;AAEAA,IAAAA,CAAC,CAAC,CAAD,CAAD,IAAQN,CAAC,CAAC,CAAD,CAAD,GAAOC,CAAC,CAAC,CAAD,CAAhB;AACAK,IAAAA,CAAC,CAAC,CAAD,CAAD,IAAQA,CAAC,CAAC,CAAD,CAAD,KAAS,EAAjB;AACAA,IAAAA,CAAC,CAAC,CAAD,CAAD,IAAQ,MAAR;AAEAA,IAAAA,CAAC,CAAC,CAAD,CAAD,IAAQN,CAAC,CAAC,CAAD,CAAD,GAAOC,CAAC,CAAC,CAAD,CAAhB;AACAK,IAAAA,CAAC,CAAC,CAAD,CAAD,IAAQA,CAAC,CAAC,CAAD,CAAD,KAAS,EAAjB;AACAA,IAAAA,CAAC,CAAC,CAAD,CAAD,IAAQ,MAAR;AAEAA,IAAAA,CAAC,CAAC,CAAD,CAAD,IAAQN,CAAC,CAAC,CAAD,CAAD,GAAOC,CAAC,CAAC,CAAD,CAAhB;AACAK,IAAAA,CAAC,CAAC,CAAD,CAAD,IAAQA,CAAC,CAAC,CAAD,CAAD,KAAS,EAAjB;AACAA,IAAAA,CAAC,CAAC,CAAD,CAAD,IAAQ,MAAR;AAEAA,IAAAA,CAAC,CAAC,CAAD,CAAD,IAAQN,CAAC,CAAC,CAAD,CAAD,GAAOC,CAAC,CAAC,CAAD,CAAhB;AACAK,IAAAA,CAAC,CAAC,CAAD,CAAD,IAAQA,CAAC,CAAC,CAAD,CAAD,KAAS,EAAjB;AACAA,IAAAA,CAAC,CAAC,CAAD,CAAD,IAAQ,MAAR;AAEAA,IAAAA,CAAC,CAAC,CAAD,CAAD,IAASN,CAAC,CAAC,CAAD,CAAD,GAAOC,CAAC,CAAC,CAAD,CAAT,GAAiBD,CAAC,CAAC,CAAD,CAAD,GAAOC,CAAC,CAAC,CAAD,CAAzB,GAAiCD,CAAC,CAAC,CAAD,CAAD,GAAOC,CAAC,CAAC,CAAD,CAAzC,GAAiDD,CAAC,CAAC,CAAD,CAAD,GAAOC,CAAC,CAAC,CAAD,CAAjE;AACAK,IAAAA,CAAC,CAAC,CAAD,CAAD,IAAQ,MAAR;AAEA,WAAO,CAAEA,CAAC,CAAC,CAAD,CAAD,IAAQ,EAAT,GAAeA,CAAC,CAAC,CAAD,CAAjB,EAAuBA,CAAC,CAAC,CAAD,CAAD,IAAQ,EAAT,GAAeA,CAAC,CAAC,CAAD,CAAtC,CAAP;AACH;;AAED,WAASE,QAAT,CAAkBR,CAAlB,EAAqBC,CAArB,EAAwB;AACpB;AACA;AACA;AACA;AACA;AAEAA,IAAAA,CAAC,IAAI,EAAL;;AAEA,QAAIA,CAAC,KAAK,EAAV,EAAc;AACV,aAAO,CAACD,CAAC,CAAC,CAAD,CAAF,EAAOA,CAAC,CAAC,CAAD,CAAR,CAAP;AACH,KAFD,MAEO,IAAIC,CAAC,GAAG,EAAR,EAAY;AACf,aAAO,CAAED,CAAC,CAAC,CAAD,CAAD,IAAQC,CAAT,GAAeD,CAAC,CAAC,CAAD,CAAD,KAAU,KAAKC,CAA/B,EAAqCD,CAAC,CAAC,CAAD,CAAD,IAAQC,CAAT,GAAeD,CAAC,CAAC,CAAD,CAAD,KAAU,KAAKC,CAAlE,CAAP;AACH,KAFM,MAEA;AACHA,MAAAA,CAAC,IAAI,EAAL;AACA,aAAO,CAAED,CAAC,CAAC,CAAD,CAAD,IAAQC,CAAT,GAAeD,CAAC,CAAC,CAAD,CAAD,KAAU,KAAKC,CAA/B,EAAqCD,CAAC,CAAC,CAAD,CAAD,IAAQC,CAAT,GAAeD,CAAC,CAAC,CAAD,CAAD,KAAU,KAAKC,CAAlE,CAAP;AACH;AACJ;;AAED,WAASQ,aAAT,CAAuBT,CAAvB,EAA0BC,CAA1B,EAA6B;AACzB;AACA;AACA;AACA;AACA;AAEAA,IAAAA,CAAC,IAAI,EAAL;;AAEA,QAAIA,CAAC,KAAK,CAAV,EAAa;AACT,aAAOD,CAAP;AACH,KAFD,MAEO,IAAIC,CAAC,GAAG,EAAR,EAAY;AACf,aAAO,CAAED,CAAC,CAAC,CAAD,CAAD,IAAQC,CAAT,GAAeD,CAAC,CAAC,CAAD,CAAD,KAAU,KAAKC,CAA/B,EAAoCD,CAAC,CAAC,CAAD,CAAD,IAAQC,CAA5C,CAAP;AACH,KAFM,MAEA;AACH,aAAO,CAACD,CAAC,CAAC,CAAD,CAAD,IAASC,CAAC,GAAG,EAAd,EAAmB,CAAnB,CAAP;AACH;AACJ;;AAED,WAASS,OAAT,CAAiBV,CAAjB,EAAoBC,CAApB,EAAuB;AACnB;AACA;AACA;AACA;AAEA,WAAO,CAACD,CAAC,CAAC,CAAD,CAAD,GAAOC,CAAC,CAAC,CAAD,CAAT,EAAcD,CAAC,CAAC,CAAD,CAAD,GAAOC,CAAC,CAAC,CAAD,CAAtB,CAAP;AACH;;AAED,WAASU,QAAT,CAAkBP,CAAlB,EAAqB;AACjB;AACA;AACA;AACA;AACA;AAEAA,IAAAA,CAAC,GAAGM,OAAO,CAACN,CAAD,EAAI,CAAC,CAAD,EAAIA,CAAC,CAAC,CAAD,CAAD,KAAS,CAAb,CAAJ,CAAX;AACAA,IAAAA,CAAC,GAAGG,YAAY,CAACH,CAAD,EAAI,CAAC,UAAD,EAAa,UAAb,CAAJ,CAAhB;AACAA,IAAAA,CAAC,GAAGM,OAAO,CAACN,CAAD,EAAI,CAAC,CAAD,EAAIA,CAAC,CAAC,CAAD,CAAD,KAAS,CAAb,CAAJ,CAAX;AACAA,IAAAA,CAAC,GAAGG,YAAY,CAACH,CAAD,EAAI,CAAC,UAAD,EAAa,UAAb,CAAJ,CAAhB;AACAA,IAAAA,CAAC,GAAGM,OAAO,CAACN,CAAD,EAAI,CAAC,CAAD,EAAIA,CAAC,CAAC,CAAD,CAAD,KAAS,CAAb,CAAJ,CAAX;AAEA,WAAOA,CAAP;AACH,GA7LwB,CA+LzB;AACA;;;AAEAhB,EAAAA,OAAO,CAACwB,GAAR,CAAYC,MAAZ,GAAqB,UAAUvB,KAAV,EAAiBwB,IAAjB,EAAuB;AACxC;AACA;AACA;AACA;AACA,QAAI1B,OAAO,CAAC2B,eAAR,IAA2B,CAAC1B,WAAW,CAACC,KAAD,CAA3C,EAAoD;AAChD,aAAOH,SAAP;AACH;;AACD2B,IAAAA,IAAI,GAAGA,IAAI,IAAI,CAAf;AAEA,QAAIE,SAAS,GAAG1B,KAAK,CAACM,MAAN,GAAe,CAA/B;AACA,QAAIqB,MAAM,GAAG3B,KAAK,CAACM,MAAN,GAAeoB,SAA5B;AAEA,QAAIE,EAAE,GAAGJ,IAAT;AAEA,QAAIK,EAAE,GAAG,CAAT;AAEA,QAAIC,EAAE,GAAG,UAAT;AACA,QAAIC,EAAE,GAAG,UAAT;;AAEA,SAAK,IAAI1B,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGsB,MAApB,EAA4BtB,CAAC,GAAGA,CAAC,GAAG,CAApC,EAAuC;AACnCwB,MAAAA,EAAE,GAAI7B,KAAK,CAACK,CAAD,CAAN,GAAcL,KAAK,CAACK,CAAC,GAAG,CAAL,CAAL,IAAgB,CAA9B,GAAoCL,KAAK,CAACK,CAAC,GAAG,CAAL,CAAL,IAAgB,EAApD,GAA2DL,KAAK,CAACK,CAAC,GAAG,CAAL,CAAL,IAAgB,EAAhF;AAEAwB,MAAAA,EAAE,GAAGpB,YAAY,CAACoB,EAAD,EAAKC,EAAL,CAAjB;AACAD,MAAAA,EAAE,GAAGjB,QAAQ,CAACiB,EAAD,EAAK,EAAL,CAAb;AACAA,MAAAA,EAAE,GAAGpB,YAAY,CAACoB,EAAD,EAAKE,EAAL,CAAjB;AAEAH,MAAAA,EAAE,IAAIC,EAAN;AACAD,MAAAA,EAAE,GAAGhB,QAAQ,CAACgB,EAAD,EAAK,EAAL,CAAb;AACAA,MAAAA,EAAE,GAAGnB,YAAY,CAACmB,EAAD,EAAK,CAAL,CAAZ,GAAsB,UAA3B;AACH;;AAEDC,IAAAA,EAAE,GAAG,CAAL;;AAEA,YAAQH,SAAR;AACI,WAAK,CAAL;AACIG,QAAAA,EAAE,IAAI7B,KAAK,CAACK,CAAC,GAAG,CAAL,CAAL,IAAgB,EAAtB;;AAEJ,WAAK,CAAL;AACIwB,QAAAA,EAAE,IAAI7B,KAAK,CAACK,CAAC,GAAG,CAAL,CAAL,IAAgB,CAAtB;;AAEJ,WAAK,CAAL;AACIwB,QAAAA,EAAE,IAAI7B,KAAK,CAACK,CAAD,CAAX;AACAwB,QAAAA,EAAE,GAAGpB,YAAY,CAACoB,EAAD,EAAKC,EAAL,CAAjB;AACAD,QAAAA,EAAE,GAAGjB,QAAQ,CAACiB,EAAD,EAAK,EAAL,CAAb;AACAA,QAAAA,EAAE,GAAGpB,YAAY,CAACoB,EAAD,EAAKE,EAAL,CAAjB;AACAH,QAAAA,EAAE,IAAIC,EAAN;AAZR;;AAeAD,IAAAA,EAAE,IAAI5B,KAAK,CAACM,MAAZ;AACAsB,IAAAA,EAAE,GAAGf,QAAQ,CAACe,EAAD,CAAb;AAEA,WAAOA,EAAE,KAAK,CAAd;AACH,GArDD;;AAuDA9B,EAAAA,OAAO,CAACwB,GAAR,CAAYU,OAAZ,GAAsB,UAAUhC,KAAV,EAAiBwB,IAAjB,EAAuB;AACzC;AACA;AACA;AACA;AACA,QAAI1B,OAAO,CAAC2B,eAAR,IAA2B,CAAC1B,WAAW,CAACC,KAAD,CAA3C,EAAoD;AAChD,aAAOH,SAAP;AACH;;AAED2B,IAAAA,IAAI,GAAGA,IAAI,IAAI,CAAf;AACA,QAAIE,SAAS,GAAG1B,KAAK,CAACM,MAAN,GAAe,EAA/B;AACA,QAAIqB,MAAM,GAAG3B,KAAK,CAACM,MAAN,GAAeoB,SAA5B;AAEA,QAAIE,EAAE,GAAGJ,IAAT;AACA,QAAIS,EAAE,GAAGT,IAAT;AACA,QAAIU,EAAE,GAAGV,IAAT;AACA,QAAIW,EAAE,GAAGX,IAAT;AAEA,QAAIK,EAAE,GAAG,CAAT;AACA,QAAIO,EAAE,GAAG,CAAT;AACA,QAAIC,EAAE,GAAG,CAAT;AACA,QAAIC,EAAE,GAAG,CAAT;AAEA,QAAIR,EAAE,GAAG,UAAT;AACA,QAAIC,EAAE,GAAG,UAAT;AACA,QAAIQ,EAAE,GAAG,UAAT;AACA,QAAIC,EAAE,GAAG,UAAT;;AAEA,SAAK,IAAInC,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGsB,MAApB,EAA4BtB,CAAC,GAAGA,CAAC,GAAG,EAApC,EAAwC;AACpCwB,MAAAA,EAAE,GAAI7B,KAAK,CAACK,CAAD,CAAN,GAAcL,KAAK,CAACK,CAAC,GAAG,CAAL,CAAL,IAAgB,CAA9B,GAAoCL,KAAK,CAACK,CAAC,GAAG,CAAL,CAAL,IAAgB,EAApD,GAA2DL,KAAK,CAACK,CAAC,GAAG,CAAL,CAAL,IAAgB,EAAhF;AACA+B,MAAAA,EAAE,GAAIpC,KAAK,CAACK,CAAC,GAAG,CAAL,CAAN,GAAkBL,KAAK,CAACK,CAAC,GAAG,CAAL,CAAL,IAAgB,CAAlC,GAAwCL,KAAK,CAACK,CAAC,GAAG,CAAL,CAAL,IAAgB,EAAxD,GAA+DL,KAAK,CAACK,CAAC,GAAG,CAAL,CAAL,IAAgB,EAApF;AACAgC,MAAAA,EAAE,GAAIrC,KAAK,CAACK,CAAC,GAAG,CAAL,CAAN,GAAkBL,KAAK,CAACK,CAAC,GAAG,CAAL,CAAL,IAAgB,CAAlC,GAAwCL,KAAK,CAACK,CAAC,GAAG,EAAL,CAAL,IAAiB,EAAzD,GAAgEL,KAAK,CAACK,CAAC,GAAG,EAAL,CAAL,IAAiB,EAAtF;AACAiC,MAAAA,EAAE,GAAItC,KAAK,CAACK,CAAC,GAAG,EAAL,CAAN,GAAmBL,KAAK,CAACK,CAAC,GAAG,EAAL,CAAL,IAAiB,CAApC,GAA0CL,KAAK,CAACK,CAAC,GAAG,EAAL,CAAL,IAAiB,EAA3D,GAAkEL,KAAK,CAACK,CAAC,GAAG,EAAL,CAAL,IAAiB,EAAxF;AAEAwB,MAAAA,EAAE,GAAGpB,YAAY,CAACoB,EAAD,EAAKC,EAAL,CAAjB;AACAD,MAAAA,EAAE,GAAGjB,QAAQ,CAACiB,EAAD,EAAK,EAAL,CAAb;AACAA,MAAAA,EAAE,GAAGpB,YAAY,CAACoB,EAAD,EAAKE,EAAL,CAAjB;AACAH,MAAAA,EAAE,IAAIC,EAAN;AAEAD,MAAAA,EAAE,GAAGhB,QAAQ,CAACgB,EAAD,EAAK,EAAL,CAAb;AACAA,MAAAA,EAAE,IAAIK,EAAN;AACAL,MAAAA,EAAE,GAAGnB,YAAY,CAACmB,EAAD,EAAK,CAAL,CAAZ,GAAsB,UAA3B;AAEAQ,MAAAA,EAAE,GAAG3B,YAAY,CAAC2B,EAAD,EAAKL,EAAL,CAAjB;AACAK,MAAAA,EAAE,GAAGxB,QAAQ,CAACwB,EAAD,EAAK,EAAL,CAAb;AACAA,MAAAA,EAAE,GAAG3B,YAAY,CAAC2B,EAAD,EAAKG,EAAL,CAAjB;AACAN,MAAAA,EAAE,IAAIG,EAAN;AAEAH,MAAAA,EAAE,GAAGrB,QAAQ,CAACqB,EAAD,EAAK,EAAL,CAAb;AACAA,MAAAA,EAAE,IAAIC,EAAN;AACAD,MAAAA,EAAE,GAAGxB,YAAY,CAACwB,EAAD,EAAK,CAAL,CAAZ,GAAsB,UAA3B;AAEAI,MAAAA,EAAE,GAAG5B,YAAY,CAAC4B,EAAD,EAAKE,EAAL,CAAjB;AACAF,MAAAA,EAAE,GAAGzB,QAAQ,CAACyB,EAAD,EAAK,EAAL,CAAb;AACAA,MAAAA,EAAE,GAAG5B,YAAY,CAAC4B,EAAD,EAAKG,EAAL,CAAjB;AACAN,MAAAA,EAAE,IAAIG,EAAN;AAEAH,MAAAA,EAAE,GAAGtB,QAAQ,CAACsB,EAAD,EAAK,EAAL,CAAb;AACAA,MAAAA,EAAE,IAAIC,EAAN;AACAD,MAAAA,EAAE,GAAGzB,YAAY,CAACyB,EAAD,EAAK,CAAL,CAAZ,GAAsB,UAA3B;AAEAI,MAAAA,EAAE,GAAG7B,YAAY,CAAC6B,EAAD,EAAKE,EAAL,CAAjB;AACAF,MAAAA,EAAE,GAAG1B,QAAQ,CAAC0B,EAAD,EAAK,EAAL,CAAb;AACAA,MAAAA,EAAE,GAAG7B,YAAY,CAAC6B,EAAD,EAAKR,EAAL,CAAjB;AACAK,MAAAA,EAAE,IAAIG,EAAN;AAEAH,MAAAA,EAAE,GAAGvB,QAAQ,CAACuB,EAAD,EAAK,EAAL,CAAb;AACAA,MAAAA,EAAE,IAAIP,EAAN;AACAO,MAAAA,EAAE,GAAG1B,YAAY,CAAC0B,EAAD,EAAK,CAAL,CAAZ,GAAsB,UAA3B;AACH;;AAEDN,IAAAA,EAAE,GAAG,CAAL;AACAO,IAAAA,EAAE,GAAG,CAAL;AACAC,IAAAA,EAAE,GAAG,CAAL;AACAC,IAAAA,EAAE,GAAG,CAAL;;AAEA,YAAQZ,SAAR;AACI,WAAK,EAAL;AACIY,QAAAA,EAAE,IAAItC,KAAK,CAACK,CAAC,GAAG,EAAL,CAAL,IAAiB,EAAvB;;AAEJ,WAAK,EAAL;AACIiC,QAAAA,EAAE,IAAItC,KAAK,CAACK,CAAC,GAAG,EAAL,CAAL,IAAiB,CAAvB;;AAEJ,WAAK,EAAL;AACIiC,QAAAA,EAAE,IAAItC,KAAK,CAACK,CAAC,GAAG,EAAL,CAAX;AACAiC,QAAAA,EAAE,GAAG7B,YAAY,CAAC6B,EAAD,EAAKE,EAAL,CAAjB;AACAF,QAAAA,EAAE,GAAG1B,QAAQ,CAAC0B,EAAD,EAAK,EAAL,CAAb;AACAA,QAAAA,EAAE,GAAG7B,YAAY,CAAC6B,EAAD,EAAKR,EAAL,CAAjB;AACAK,QAAAA,EAAE,IAAIG,EAAN;;AAEJ,WAAK,EAAL;AACID,QAAAA,EAAE,IAAIrC,KAAK,CAACK,CAAC,GAAG,EAAL,CAAL,IAAiB,EAAvB;;AAEJ,WAAK,EAAL;AACIgC,QAAAA,EAAE,IAAIrC,KAAK,CAACK,CAAC,GAAG,EAAL,CAAL,IAAiB,EAAvB;;AAEJ,WAAK,EAAL;AACIgC,QAAAA,EAAE,IAAIrC,KAAK,CAACK,CAAC,GAAG,CAAL,CAAL,IAAgB,CAAtB;;AAEJ,WAAK,CAAL;AACIgC,QAAAA,EAAE,IAAIrC,KAAK,CAACK,CAAC,GAAG,CAAL,CAAX;AACAgC,QAAAA,EAAE,GAAG5B,YAAY,CAAC4B,EAAD,EAAKE,EAAL,CAAjB;AACAF,QAAAA,EAAE,GAAGzB,QAAQ,CAACyB,EAAD,EAAK,EAAL,CAAb;AACAA,QAAAA,EAAE,GAAG5B,YAAY,CAAC4B,EAAD,EAAKG,EAAL,CAAjB;AACAN,QAAAA,EAAE,IAAIG,EAAN;;AAEJ,WAAK,CAAL;AACID,QAAAA,EAAE,IAAIpC,KAAK,CAACK,CAAC,GAAG,CAAL,CAAL,IAAgB,EAAtB;;AAEJ,WAAK,CAAL;AACI+B,QAAAA,EAAE,IAAIpC,KAAK,CAACK,CAAC,GAAG,CAAL,CAAL,IAAgB,EAAtB;;AAEJ,WAAK,CAAL;AACI+B,QAAAA,EAAE,IAAIpC,KAAK,CAACK,CAAC,GAAG,CAAL,CAAL,IAAgB,CAAtB;;AAEJ,WAAK,CAAL;AACI+B,QAAAA,EAAE,IAAIpC,KAAK,CAACK,CAAC,GAAG,CAAL,CAAX;AACA+B,QAAAA,EAAE,GAAG3B,YAAY,CAAC2B,EAAD,EAAKL,EAAL,CAAjB;AACAK,QAAAA,EAAE,GAAGxB,QAAQ,CAACwB,EAAD,EAAK,EAAL,CAAb;AACAA,QAAAA,EAAE,GAAG3B,YAAY,CAAC2B,EAAD,EAAKG,EAAL,CAAjB;AACAN,QAAAA,EAAE,IAAIG,EAAN;;AAEJ,WAAK,CAAL;AACIP,QAAAA,EAAE,IAAI7B,KAAK,CAACK,CAAC,GAAG,CAAL,CAAL,IAAgB,EAAtB;;AAEJ,WAAK,CAAL;AACIwB,QAAAA,EAAE,IAAI7B,KAAK,CAACK,CAAC,GAAG,CAAL,CAAL,IAAgB,EAAtB;;AAEJ,WAAK,CAAL;AACIwB,QAAAA,EAAE,IAAI7B,KAAK,CAACK,CAAC,GAAG,CAAL,CAAL,IAAgB,CAAtB;;AAEJ,WAAK,CAAL;AACIwB,QAAAA,EAAE,IAAI7B,KAAK,CAACK,CAAD,CAAX;AACAwB,QAAAA,EAAE,GAAGpB,YAAY,CAACoB,EAAD,EAAKC,EAAL,CAAjB;AACAD,QAAAA,EAAE,GAAGjB,QAAQ,CAACiB,EAAD,EAAK,EAAL,CAAb;AACAA,QAAAA,EAAE,GAAGpB,YAAY,CAACoB,EAAD,EAAKE,EAAL,CAAjB;AACAH,QAAAA,EAAE,IAAIC,EAAN;AA5DR;;AA+DAD,IAAAA,EAAE,IAAI5B,KAAK,CAACM,MAAZ;AACA2B,IAAAA,EAAE,IAAIjC,KAAK,CAACM,MAAZ;AACA4B,IAAAA,EAAE,IAAIlC,KAAK,CAACM,MAAZ;AACA6B,IAAAA,EAAE,IAAInC,KAAK,CAACM,MAAZ;AAEAsB,IAAAA,EAAE,IAAIK,EAAN;AACAL,IAAAA,EAAE,IAAIM,EAAN;AACAN,IAAAA,EAAE,IAAIO,EAAN;AACAF,IAAAA,EAAE,IAAIL,EAAN;AACAM,IAAAA,EAAE,IAAIN,EAAN;AACAO,IAAAA,EAAE,IAAIP,EAAN;AAEAA,IAAAA,EAAE,GAAGf,QAAQ,CAACe,EAAD,CAAb;AACAK,IAAAA,EAAE,GAAGpB,QAAQ,CAACoB,EAAD,CAAb;AACAC,IAAAA,EAAE,GAAGrB,QAAQ,CAACqB,EAAD,CAAb;AACAC,IAAAA,EAAE,GAAGtB,QAAQ,CAACsB,EAAD,CAAb;AAEAP,IAAAA,EAAE,IAAIK,EAAN;AACAL,IAAAA,EAAE,IAAIM,EAAN;AACAN,IAAAA,EAAE,IAAIO,EAAN;AACAF,IAAAA,EAAE,IAAIL,EAAN;AACAM,IAAAA,EAAE,IAAIN,EAAN;AACAO,IAAAA,EAAE,IAAIP,EAAN;AAEA,WAAO,CAAC,aAAa,CAACA,EAAE,KAAK,CAAR,EAAWa,QAAX,CAAoB,EAApB,CAAd,EAAuCC,KAAvC,CAA6C,CAAC,CAA9C,IAAmD,CAAC,aAAa,CAACT,EAAE,KAAK,CAAR,EAAWQ,QAAX,CAAoB,EAApB,CAAd,EAAuCC,KAAvC,CAA6C,CAAC,CAA9C,CAAnD,GAAsG,CAAC,aAAa,CAACR,EAAE,KAAK,CAAR,EAAWO,QAAX,CAAoB,EAApB,CAAd,EAAuCC,KAAvC,CAA6C,CAAC,CAA9C,CAAtG,GAAyJ,CAAC,aAAa,CAACP,EAAE,KAAK,CAAR,EAAWM,QAAX,CAAoB,EAApB,CAAd,EAAuCC,KAAvC,CAA6C,CAAC,CAA9C,CAAhK;AACH,GApKD;;AAsKA5C,EAAAA,OAAO,CAAC6C,GAAR,CAAYX,OAAZ,GAAsB,UAAUhC,KAAV,EAAiBwB,IAAjB,EAAuB;AACzC;AACA;AACA;AACA;AACA,QAAI1B,OAAO,CAAC2B,eAAR,IAA2B,CAAC1B,WAAW,CAACC,KAAD,CAA3C,EAAoD;AAChD,aAAOH,SAAP;AACH;;AACD2B,IAAAA,IAAI,GAAGA,IAAI,IAAI,CAAf;AAEA,QAAIE,SAAS,GAAG1B,KAAK,CAACM,MAAN,GAAe,EAA/B;AACA,QAAIqB,MAAM,GAAG3B,KAAK,CAACM,MAAN,GAAeoB,SAA5B;AAEA,QAAIE,EAAE,GAAG,CAAC,CAAD,EAAIJ,IAAJ,CAAT;AACA,QAAIS,EAAE,GAAG,CAAC,CAAD,EAAIT,IAAJ,CAAT;AAEA,QAAIK,EAAE,GAAG,CAAC,CAAD,EAAI,CAAJ,CAAT;AACA,QAAIO,EAAE,GAAG,CAAC,CAAD,EAAI,CAAJ,CAAT;AAEA,QAAIN,EAAE,GAAG,CAAC,UAAD,EAAa,UAAb,CAAT;AACA,QAAIC,EAAE,GAAG,CAAC,UAAD,EAAa,UAAb,CAAT;;AAEA,SAAK,IAAI1B,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGsB,MAApB,EAA4BtB,CAAC,GAAGA,CAAC,GAAG,EAApC,EAAwC;AACpCwB,MAAAA,EAAE,GAAG,CAAE7B,KAAK,CAACK,CAAC,GAAG,CAAL,CAAN,GAAkBL,KAAK,CAACK,CAAC,GAAG,CAAL,CAAL,IAAgB,CAAlC,GAAwCL,KAAK,CAACK,CAAC,GAAG,CAAL,CAAL,IAAgB,EAAxD,GAA+DL,KAAK,CAACK,CAAC,GAAG,CAAL,CAAL,IAAgB,EAAhF,EAAsFL,KAAK,CAACK,CAAD,CAAN,GACrFL,KAAK,CAACK,CAAC,GAAG,CAAL,CAAL,IAAgB,CADqE,GAC/DL,KAAK,CAACK,CAAC,GAAG,CAAL,CAAL,IAAgB,EAD+C,GACxCL,KAAK,CAACK,CAAC,GAAG,CAAL,CAAL,IAAgB,EAD7D,CAAL;AAEA+B,MAAAA,EAAE,GAAG,CAAEpC,KAAK,CAACK,CAAC,GAAG,EAAL,CAAN,GAAmBL,KAAK,CAACK,CAAC,GAAG,EAAL,CAAL,IAAiB,CAApC,GAA0CL,KAAK,CAACK,CAAC,GAAG,EAAL,CAAL,IAAiB,EAA3D,GAAkEL,KAAK,CAACK,CAAC,GAAG,EAAL,CAAL,IAAiB,EAApF,EAA0FL,KAAK,CAACK,CAAC,GAAG,CAAL,CAAN,GACzFL,KAAK,CAACK,CAAC,GAAG,CAAL,CAAL,IAAgB,CADyE,GACnEL,KAAK,CAACK,CAAC,GAAG,EAAL,CAAL,IAAiB,EADkD,GAC3CL,KAAK,CAACK,CAAC,GAAG,EAAL,CAAL,IAAiB,EAD/D,CAAL;AAGAwB,MAAAA,EAAE,GAAGZ,YAAY,CAACY,EAAD,EAAKC,EAAL,CAAjB;AACAD,MAAAA,EAAE,GAAGX,QAAQ,CAACW,EAAD,EAAK,EAAL,CAAb;AACAA,MAAAA,EAAE,GAAGZ,YAAY,CAACY,EAAD,EAAKE,EAAL,CAAjB;AACAH,MAAAA,EAAE,GAAGR,OAAO,CAACQ,EAAD,EAAKC,EAAL,CAAZ;AAEAD,MAAAA,EAAE,GAAGV,QAAQ,CAACU,EAAD,EAAK,EAAL,CAAb;AACAA,MAAAA,EAAE,GAAGb,OAAO,CAACa,EAAD,EAAKK,EAAL,CAAZ;AACAL,MAAAA,EAAE,GAAGb,OAAO,CAACE,YAAY,CAACW,EAAD,EAAK,CAAC,CAAD,EAAI,CAAJ,CAAL,CAAb,EAA2B,CAAC,CAAD,EAAI,UAAJ,CAA3B,CAAZ;AAEAQ,MAAAA,EAAE,GAAGnB,YAAY,CAACmB,EAAD,EAAKL,EAAL,CAAjB;AACAK,MAAAA,EAAE,GAAGlB,QAAQ,CAACkB,EAAD,EAAK,EAAL,CAAb;AACAA,MAAAA,EAAE,GAAGnB,YAAY,CAACmB,EAAD,EAAKN,EAAL,CAAjB;AACAG,MAAAA,EAAE,GAAGb,OAAO,CAACa,EAAD,EAAKG,EAAL,CAAZ;AAEAH,MAAAA,EAAE,GAAGf,QAAQ,CAACe,EAAD,EAAK,EAAL,CAAb;AACAA,MAAAA,EAAE,GAAGlB,OAAO,CAACkB,EAAD,EAAKL,EAAL,CAAZ;AACAK,MAAAA,EAAE,GAAGlB,OAAO,CAACE,YAAY,CAACgB,EAAD,EAAK,CAAC,CAAD,EAAI,CAAJ,CAAL,CAAb,EAA2B,CAAC,CAAD,EAAI,UAAJ,CAA3B,CAAZ;AACH;;AAEDJ,IAAAA,EAAE,GAAG,CAAC,CAAD,EAAI,CAAJ,CAAL;AACAO,IAAAA,EAAE,GAAG,CAAC,CAAD,EAAI,CAAJ,CAAL;;AAEA,YAAQV,SAAR;AACI,WAAK,EAAL;AACIU,QAAAA,EAAE,GAAGhB,OAAO,CAACgB,EAAD,EAAKjB,aAAa,CAAC,CAAC,CAAD,EAAInB,KAAK,CAACK,CAAC,GAAG,EAAL,CAAT,CAAD,EAAqB,EAArB,CAAlB,CAAZ;;AAEJ,WAAK,EAAL;AACI+B,QAAAA,EAAE,GAAGhB,OAAO,CAACgB,EAAD,EAAKjB,aAAa,CAAC,CAAC,CAAD,EAAInB,KAAK,CAACK,CAAC,GAAG,EAAL,CAAT,CAAD,EAAqB,EAArB,CAAlB,CAAZ;;AAEJ,WAAK,EAAL;AACI+B,QAAAA,EAAE,GAAGhB,OAAO,CAACgB,EAAD,EAAKjB,aAAa,CAAC,CAAC,CAAD,EAAInB,KAAK,CAACK,CAAC,GAAG,EAAL,CAAT,CAAD,EAAqB,EAArB,CAAlB,CAAZ;;AAEJ,WAAK,EAAL;AACI+B,QAAAA,EAAE,GAAGhB,OAAO,CAACgB,EAAD,EAAKjB,aAAa,CAAC,CAAC,CAAD,EAAInB,KAAK,CAACK,CAAC,GAAG,EAAL,CAAT,CAAD,EAAqB,EAArB,CAAlB,CAAZ;;AAEJ,WAAK,EAAL;AACI+B,QAAAA,EAAE,GAAGhB,OAAO,CAACgB,EAAD,EAAKjB,aAAa,CAAC,CAAC,CAAD,EAAInB,KAAK,CAACK,CAAC,GAAG,EAAL,CAAT,CAAD,EAAqB,EAArB,CAAlB,CAAZ;;AAEJ,WAAK,EAAL;AACI+B,QAAAA,EAAE,GAAGhB,OAAO,CAACgB,EAAD,EAAKjB,aAAa,CAAC,CAAC,CAAD,EAAInB,KAAK,CAACK,CAAC,GAAG,CAAL,CAAT,CAAD,EAAoB,CAApB,CAAlB,CAAZ;;AAEJ,WAAK,CAAL;AACI+B,QAAAA,EAAE,GAAGhB,OAAO,CAACgB,EAAD,EAAK,CAAC,CAAD,EAAIpC,KAAK,CAACK,CAAC,GAAG,CAAL,CAAT,CAAL,CAAZ;AACA+B,QAAAA,EAAE,GAAGnB,YAAY,CAACmB,EAAD,EAAKL,EAAL,CAAjB;AACAK,QAAAA,EAAE,GAAGlB,QAAQ,CAACkB,EAAD,EAAK,EAAL,CAAb;AACAA,QAAAA,EAAE,GAAGnB,YAAY,CAACmB,EAAD,EAAKN,EAAL,CAAjB;AACAG,QAAAA,EAAE,GAAGb,OAAO,CAACa,EAAD,EAAKG,EAAL,CAAZ;;AAEJ,WAAK,CAAL;AACIP,QAAAA,EAAE,GAAGT,OAAO,CAACS,EAAD,EAAKV,aAAa,CAAC,CAAC,CAAD,EAAInB,KAAK,CAACK,CAAC,GAAG,CAAL,CAAT,CAAD,EAAoB,EAApB,CAAlB,CAAZ;;AAEJ,WAAK,CAAL;AACIwB,QAAAA,EAAE,GAAGT,OAAO,CAACS,EAAD,EAAKV,aAAa,CAAC,CAAC,CAAD,EAAInB,KAAK,CAACK,CAAC,GAAG,CAAL,CAAT,CAAD,EAAoB,EAApB,CAAlB,CAAZ;;AAEJ,WAAK,CAAL;AACIwB,QAAAA,EAAE,GAAGT,OAAO,CAACS,EAAD,EAAKV,aAAa,CAAC,CAAC,CAAD,EAAInB,KAAK,CAACK,CAAC,GAAG,CAAL,CAAT,CAAD,EAAoB,EAApB,CAAlB,CAAZ;;AAEJ,WAAK,CAAL;AACIwB,QAAAA,EAAE,GAAGT,OAAO,CAACS,EAAD,EAAKV,aAAa,CAAC,CAAC,CAAD,EAAInB,KAAK,CAACK,CAAC,GAAG,CAAL,CAAT,CAAD,EAAoB,EAApB,CAAlB,CAAZ;;AAEJ,WAAK,CAAL;AACIwB,QAAAA,EAAE,GAAGT,OAAO,CAACS,EAAD,EAAKV,aAAa,CAAC,CAAC,CAAD,EAAInB,KAAK,CAACK,CAAC,GAAG,CAAL,CAAT,CAAD,EAAoB,EAApB,CAAlB,CAAZ;;AAEJ,WAAK,CAAL;AACIwB,QAAAA,EAAE,GAAGT,OAAO,CAACS,EAAD,EAAKV,aAAa,CAAC,CAAC,CAAD,EAAInB,KAAK,CAACK,CAAC,GAAG,CAAL,CAAT,CAAD,EAAoB,EAApB,CAAlB,CAAZ;;AAEJ,WAAK,CAAL;AACIwB,QAAAA,EAAE,GAAGT,OAAO,CAACS,EAAD,EAAKV,aAAa,CAAC,CAAC,CAAD,EAAInB,KAAK,CAACK,CAAC,GAAG,CAAL,CAAT,CAAD,EAAoB,CAApB,CAAlB,CAAZ;;AAEJ,WAAK,CAAL;AACIwB,QAAAA,EAAE,GAAGT,OAAO,CAACS,EAAD,EAAK,CAAC,CAAD,EAAI7B,KAAK,CAACK,CAAD,CAAT,CAAL,CAAZ;AACAwB,QAAAA,EAAE,GAAGZ,YAAY,CAACY,EAAD,EAAKC,EAAL,CAAjB;AACAD,QAAAA,EAAE,GAAGX,QAAQ,CAACW,EAAD,EAAK,EAAL,CAAb;AACAA,QAAAA,EAAE,GAAGZ,YAAY,CAACY,EAAD,EAAKE,EAAL,CAAjB;AACAH,QAAAA,EAAE,GAAGR,OAAO,CAACQ,EAAD,EAAKC,EAAL,CAAZ;AApDR;;AAuDAD,IAAAA,EAAE,GAAGR,OAAO,CAACQ,EAAD,EAAK,CAAC,CAAD,EAAI5B,KAAK,CAACM,MAAV,CAAL,CAAZ;AACA2B,IAAAA,EAAE,GAAGb,OAAO,CAACa,EAAD,EAAK,CAAC,CAAD,EAAIjC,KAAK,CAACM,MAAV,CAAL,CAAZ;AAEAsB,IAAAA,EAAE,GAAGb,OAAO,CAACa,EAAD,EAAKK,EAAL,CAAZ;AACAA,IAAAA,EAAE,GAAGlB,OAAO,CAACkB,EAAD,EAAKL,EAAL,CAAZ;AAEAA,IAAAA,EAAE,GAAGP,QAAQ,CAACO,EAAD,CAAb;AACAK,IAAAA,EAAE,GAAGZ,QAAQ,CAACY,EAAD,CAAb;AAEAL,IAAAA,EAAE,GAAGb,OAAO,CAACa,EAAD,EAAKK,EAAL,CAAZ;AACAA,IAAAA,EAAE,GAAGlB,OAAO,CAACkB,EAAD,EAAKL,EAAL,CAAZ;AAEA,WAAO,CAAC,aAAa,CAACA,EAAE,CAAC,CAAD,CAAF,KAAU,CAAX,EAAca,QAAd,CAAuB,EAAvB,CAAd,EAA0CC,KAA1C,CAAgD,CAAC,CAAjD,IAAsD,CAAC,aAAa,CAACd,EAAE,CAAC,CAAD,CAAF,KAAU,CAAX,EAAca,QAAd,CAAuB,EAAvB,CAAd,EAA0CC,KAA1C,CAAgD,CAAC,CAAjD,CAAtD,GAA4G,CAAC,aAAa,CAACT,EAAE,CAAC,CAAD,CAAF,KAAU,CAAX,EAAcQ,QAAd,CAAuB,EAAvB,CAAd,EAA0CC,KAA1C,CAAgD,CAAC,CAAjD,CAA5G,GAAkK,CAAC,aAAa,CAACT,EAAE,CAAC,CAAD,CAAF,KAAU,CAAX,EAAcQ,QAAd,CAAuB,EAAvB,CAAd,EAA0CC,KAA1C,CAAgD,CAAC,CAAjD,CAAzK;AACH,GAtHD,CA/ZyB,CAuhBzB;AACA;AAEA;AACA;;;AACA,MAAI,OAAOE,OAAP,KAAmB,WAAvB,EAAoC;AAEhC,QAAI,OAAOC,MAAP,KAAkB,WAAlB,IAAiCA,MAAM,CAACD,OAA5C,EAAqD;AACjDA,MAAAA,OAAO,GAAGC,MAAM,CAACD,OAAP,GAAiB9C,OAA3B;AACH;;AAED8C,IAAAA,OAAO,CAACE,WAAR,GAAsBhD,OAAtB;AAEH,GARD,MAQO,IAAI,OAAOiD,MAAP,KAAkB,UAAlB,IAAgCA,MAAM,CAACC,GAA3C,EAAgD;AAEnDD,IAAAA,MAAM,CAAC,EAAD,EAAK,YAAY;AACnB,aAAOjD,OAAP;AACH,KAFK,CAAN;AAGH,GALM,MAKA;AAEH;AACA;AACA;AACAA,IAAAA,OAAO,CAACmD,YAAR,GAAuBrD,IAAI,CAACkD,WAA5B;;AAEAhD,IAAAA,OAAO,CAACoD,UAAR,GAAqB,YAAY;AAC7BtD,MAAAA,IAAI,CAACkD,WAAL,GAAmBhD,OAAO,CAACmD,YAA3B;AACAnD,MAAAA,OAAO,CAACmD,YAAR,GAAuBpD,SAAvB;AACAC,MAAAA,OAAO,CAACoD,UAAR,GAAqBrD,SAArB;AAEA,aAAOC,OAAP;AACH,KAND;;AAQAF,IAAAA,IAAI,CAACkD,WAAL,GAAmBhD,OAAnB;AACH;AACJ,CA1jBA,EA0jBE,IA1jBF","sourcesContent":["/* jshint -W086: true */\n// +----------------------------------------------------------------------+\n// | murmurHash3js.js v3.0.1 // https://github.com/pid/murmurHash3js\n// | A javascript implementation of MurmurHash3's x86 hashing algorithms. |\n// |----------------------------------------------------------------------|\n// | Copyright (c) 2012-2015 Karan Lyons                                       |\n// | https://github.com/karanlyons/murmurHash3.js/blob/c1778f75792abef7bdd74bc85d2d4e1a3d25cfe9/murmurHash3.js |\n// | Freely distributable under the MIT license.                          |\n// +----------------------------------------------------------------------+\n\n;(function (root, undefined) {\n    'use strict';\n\n    // Create a local object that'll be exported or referenced globally.\n    var library = {\n        'version': '3.0.0',\n        'x86': {},\n        'x64': {},\n        'inputValidation': true\n    };\n\n    // PRIVATE FUNCTIONS\n    // -----------------\n\n    function _validBytes(bytes) {\n        // check the input is an array or a typed array\n        if (!Array.isArray(bytes) && !ArrayBuffer.isView(bytes)) {\n            return false;\n        }\n\n        // check all bytes are actually bytes\n        for (var i = 0; i < bytes.length; i++) {\n            if (!Number.isInteger(bytes[i]) || bytes[i] < 0 || bytes[i] > 255) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n    function _x86Multiply(m, n) {\n        //\n        // Given two 32bit ints, returns the two multiplied together as a\n        // 32bit int.\n        //\n\n        return ((m & 0xffff) * n) + ((((m >>> 16) * n) & 0xffff) << 16);\n    }\n\n    function _x86Rotl(m, n) {\n        //\n        // Given a 32bit int and an int representing a number of bit positions,\n        // returns the 32bit int rotated left by that number of positions.\n        //\n\n        return (m << n) | (m >>> (32 - n));\n    }\n\n    function _x86Fmix(h) {\n        //\n        // Given a block, returns murmurHash3's final x86 mix of that block.\n        //\n\n        h ^= h >>> 16;\n        h = _x86Multiply(h, 0x85ebca6b);\n        h ^= h >>> 13;\n        h = _x86Multiply(h, 0xc2b2ae35);\n        h ^= h >>> 16;\n\n        return h;\n    }\n\n    function _x64Add(m, n) {\n        //\n        // Given two 64bit ints (as an array of two 32bit ints) returns the two\n        // added together as a 64bit int (as an array of two 32bit ints).\n        //\n\n        m = [m[0] >>> 16, m[0] & 0xffff, m[1] >>> 16, m[1] & 0xffff];\n        n = [n[0] >>> 16, n[0] & 0xffff, n[1] >>> 16, n[1] & 0xffff];\n        var o = [0, 0, 0, 0];\n\n        o[3] += m[3] + n[3];\n        o[2] += o[3] >>> 16;\n        o[3] &= 0xffff;\n\n        o[2] += m[2] + n[2];\n        o[1] += o[2] >>> 16;\n        o[2] &= 0xffff;\n\n        o[1] += m[1] + n[1];\n        o[0] += o[1] >>> 16;\n        o[1] &= 0xffff;\n\n        o[0] += m[0] + n[0];\n        o[0] &= 0xffff;\n\n        return [(o[0] << 16) | o[1], (o[2] << 16) | o[3]];\n    }\n\n    function _x64Multiply(m, n) {\n        //\n        // Given two 64bit ints (as an array of two 32bit ints) returns the two\n        // multiplied together as a 64bit int (as an array of two 32bit ints).\n        //\n\n        m = [m[0] >>> 16, m[0] & 0xffff, m[1] >>> 16, m[1] & 0xffff];\n        n = [n[0] >>> 16, n[0] & 0xffff, n[1] >>> 16, n[1] & 0xffff];\n        var o = [0, 0, 0, 0];\n\n        o[3] += m[3] * n[3];\n        o[2] += o[3] >>> 16;\n        o[3] &= 0xffff;\n\n        o[2] += m[2] * n[3];\n        o[1] += o[2] >>> 16;\n        o[2] &= 0xffff;\n\n        o[2] += m[3] * n[2];\n        o[1] += o[2] >>> 16;\n        o[2] &= 0xffff;\n\n        o[1] += m[1] * n[3];\n        o[0] += o[1] >>> 16;\n        o[1] &= 0xffff;\n\n        o[1] += m[2] * n[2];\n        o[0] += o[1] >>> 16;\n        o[1] &= 0xffff;\n\n        o[1] += m[3] * n[1];\n        o[0] += o[1] >>> 16;\n        o[1] &= 0xffff;\n\n        o[0] += (m[0] * n[3]) + (m[1] * n[2]) + (m[2] * n[1]) + (m[3] * n[0]);\n        o[0] &= 0xffff;\n\n        return [(o[0] << 16) | o[1], (o[2] << 16) | o[3]];\n    }\n\n    function _x64Rotl(m, n) {\n        //\n        // Given a 64bit int (as an array of two 32bit ints) and an int\n        // representing a number of bit positions, returns the 64bit int (as an\n        // array of two 32bit ints) rotated left by that number of positions.\n        //\n\n        n %= 64;\n\n        if (n === 32) {\n            return [m[1], m[0]];\n        } else if (n < 32) {\n            return [(m[0] << n) | (m[1] >>> (32 - n)), (m[1] << n) | (m[0] >>> (32 - n))];\n        } else {\n            n -= 32;\n            return [(m[1] << n) | (m[0] >>> (32 - n)), (m[0] << n) | (m[1] >>> (32 - n))];\n        }\n    }\n\n    function _x64LeftShift(m, n) {\n        //\n        // Given a 64bit int (as an array of two 32bit ints) and an int\n        // representing a number of bit positions, returns the 64bit int (as an\n        // array of two 32bit ints) shifted left by that number of positions.\n        //\n\n        n %= 64;\n\n        if (n === 0) {\n            return m;\n        } else if (n < 32) {\n            return [(m[0] << n) | (m[1] >>> (32 - n)), m[1] << n];\n        } else {\n            return [m[1] << (n - 32), 0];\n        }\n    }\n\n    function _x64Xor(m, n) {\n        //\n        // Given two 64bit ints (as an array of two 32bit ints) returns the two\n        // xored together as a 64bit int (as an array of two 32bit ints).\n        //\n\n        return [m[0] ^ n[0], m[1] ^ n[1]];\n    }\n\n    function _x64Fmix(h) {\n        //\n        // Given a block, returns murmurHash3's final x64 mix of that block.\n        // (`[0, h[0] >>> 1]` is a 33 bit unsigned right shift. This is the\n        // only place where we need to right shift 64bit ints.)\n        //\n\n        h = _x64Xor(h, [0, h[0] >>> 1]);\n        h = _x64Multiply(h, [0xff51afd7, 0xed558ccd]);\n        h = _x64Xor(h, [0, h[0] >>> 1]);\n        h = _x64Multiply(h, [0xc4ceb9fe, 0x1a85ec53]);\n        h = _x64Xor(h, [0, h[0] >>> 1]);\n\n        return h;\n    }\n\n    // PUBLIC FUNCTIONS\n    // ----------------\n\n    library.x86.hash32 = function (bytes, seed) {\n        //\n        // Given a string and an optional seed as an int, returns a 32 bit hash\n        // using the x86 flavor of MurmurHash3, as an unsigned int.\n        //\n        if (library.inputValidation && !_validBytes(bytes)) {\n            return undefined;\n        }\n        seed = seed || 0;\n\n        var remainder = bytes.length % 4;\n        var blocks = bytes.length - remainder;\n\n        var h1 = seed;\n\n        var k1 = 0;\n\n        var c1 = 0xcc9e2d51;\n        var c2 = 0x1b873593;\n\n        for (var i = 0; i < blocks; i = i + 4) {\n            k1 = (bytes[i]) | (bytes[i + 1] << 8) | (bytes[i + 2] << 16) | (bytes[i + 3] << 24);\n\n            k1 = _x86Multiply(k1, c1);\n            k1 = _x86Rotl(k1, 15);\n            k1 = _x86Multiply(k1, c2);\n\n            h1 ^= k1;\n            h1 = _x86Rotl(h1, 13);\n            h1 = _x86Multiply(h1, 5) + 0xe6546b64;\n        }\n\n        k1 = 0;\n\n        switch (remainder) {\n            case 3:\n                k1 ^= bytes[i + 2] << 16;\n\n            case 2:\n                k1 ^= bytes[i + 1] << 8;\n\n            case 1:\n                k1 ^= bytes[i];\n                k1 = _x86Multiply(k1, c1);\n                k1 = _x86Rotl(k1, 15);\n                k1 = _x86Multiply(k1, c2);\n                h1 ^= k1;\n        }\n\n        h1 ^= bytes.length;\n        h1 = _x86Fmix(h1);\n\n        return h1 >>> 0;\n    };\n\n    library.x86.hash128 = function (bytes, seed) {\n        //\n        // Given a string and an optional seed as an int, returns a 128 bit\n        // hash using the x86 flavor of MurmurHash3, as an unsigned hex.\n        //\n        if (library.inputValidation && !_validBytes(bytes)) {\n            return undefined;\n        }\n\n        seed = seed || 0;\n        var remainder = bytes.length % 16;\n        var blocks = bytes.length - remainder;\n\n        var h1 = seed;\n        var h2 = seed;\n        var h3 = seed;\n        var h4 = seed;\n\n        var k1 = 0;\n        var k2 = 0;\n        var k3 = 0;\n        var k4 = 0;\n\n        var c1 = 0x239b961b;\n        var c2 = 0xab0e9789;\n        var c3 = 0x38b34ae5;\n        var c4 = 0xa1e38b93;\n\n        for (var i = 0; i < blocks; i = i + 16) {\n            k1 = (bytes[i]) | (bytes[i + 1] << 8) | (bytes[i + 2] << 16) | (bytes[i + 3] << 24);\n            k2 = (bytes[i + 4]) | (bytes[i + 5] << 8) | (bytes[i + 6] << 16) | (bytes[i + 7] << 24);\n            k3 = (bytes[i + 8]) | (bytes[i + 9] << 8) | (bytes[i + 10] << 16) | (bytes[i + 11] << 24);\n            k4 = (bytes[i + 12]) | (bytes[i + 13] << 8) | (bytes[i + 14] << 16) | (bytes[i + 15] << 24);\n\n            k1 = _x86Multiply(k1, c1);\n            k1 = _x86Rotl(k1, 15);\n            k1 = _x86Multiply(k1, c2);\n            h1 ^= k1;\n\n            h1 = _x86Rotl(h1, 19);\n            h1 += h2;\n            h1 = _x86Multiply(h1, 5) + 0x561ccd1b;\n\n            k2 = _x86Multiply(k2, c2);\n            k2 = _x86Rotl(k2, 16);\n            k2 = _x86Multiply(k2, c3);\n            h2 ^= k2;\n\n            h2 = _x86Rotl(h2, 17);\n            h2 += h3;\n            h2 = _x86Multiply(h2, 5) + 0x0bcaa747;\n\n            k3 = _x86Multiply(k3, c3);\n            k3 = _x86Rotl(k3, 17);\n            k3 = _x86Multiply(k3, c4);\n            h3 ^= k3;\n\n            h3 = _x86Rotl(h3, 15);\n            h3 += h4;\n            h3 = _x86Multiply(h3, 5) + 0x96cd1c35;\n\n            k4 = _x86Multiply(k4, c4);\n            k4 = _x86Rotl(k4, 18);\n            k4 = _x86Multiply(k4, c1);\n            h4 ^= k4;\n\n            h4 = _x86Rotl(h4, 13);\n            h4 += h1;\n            h4 = _x86Multiply(h4, 5) + 0x32ac3b17;\n        }\n\n        k1 = 0;\n        k2 = 0;\n        k3 = 0;\n        k4 = 0;\n\n        switch (remainder) {\n            case 15:\n                k4 ^= bytes[i + 14] << 16;\n\n            case 14:\n                k4 ^= bytes[i + 13] << 8;\n\n            case 13:\n                k4 ^= bytes[i + 12];\n                k4 = _x86Multiply(k4, c4);\n                k4 = _x86Rotl(k4, 18);\n                k4 = _x86Multiply(k4, c1);\n                h4 ^= k4;\n\n            case 12:\n                k3 ^= bytes[i + 11] << 24;\n\n            case 11:\n                k3 ^= bytes[i + 10] << 16;\n\n            case 10:\n                k3 ^= bytes[i + 9] << 8;\n\n            case 9:\n                k3 ^= bytes[i + 8];\n                k3 = _x86Multiply(k3, c3);\n                k3 = _x86Rotl(k3, 17);\n                k3 = _x86Multiply(k3, c4);\n                h3 ^= k3;\n\n            case 8:\n                k2 ^= bytes[i + 7] << 24;\n\n            case 7:\n                k2 ^= bytes[i + 6] << 16;\n\n            case 6:\n                k2 ^= bytes[i + 5] << 8;\n\n            case 5:\n                k2 ^= bytes[i + 4];\n                k2 = _x86Multiply(k2, c2);\n                k2 = _x86Rotl(k2, 16);\n                k2 = _x86Multiply(k2, c3);\n                h2 ^= k2;\n\n            case 4:\n                k1 ^= bytes[i + 3] << 24;\n\n            case 3:\n                k1 ^= bytes[i + 2] << 16;\n\n            case 2:\n                k1 ^= bytes[i + 1] << 8;\n\n            case 1:\n                k1 ^= bytes[i];\n                k1 = _x86Multiply(k1, c1);\n                k1 = _x86Rotl(k1, 15);\n                k1 = _x86Multiply(k1, c2);\n                h1 ^= k1;\n        }\n\n        h1 ^= bytes.length;\n        h2 ^= bytes.length;\n        h3 ^= bytes.length;\n        h4 ^= bytes.length;\n\n        h1 += h2;\n        h1 += h3;\n        h1 += h4;\n        h2 += h1;\n        h3 += h1;\n        h4 += h1;\n\n        h1 = _x86Fmix(h1);\n        h2 = _x86Fmix(h2);\n        h3 = _x86Fmix(h3);\n        h4 = _x86Fmix(h4);\n\n        h1 += h2;\n        h1 += h3;\n        h1 += h4;\n        h2 += h1;\n        h3 += h1;\n        h4 += h1;\n\n        return (\"00000000\" + (h1 >>> 0).toString(16)).slice(-8) + (\"00000000\" + (h2 >>> 0).toString(16)).slice(-8) + (\"00000000\" + (h3 >>> 0).toString(16)).slice(-8) + (\"00000000\" + (h4 >>> 0).toString(16)).slice(-8);\n    };\n\n    library.x64.hash128 = function (bytes, seed) {\n        //\n        // Given a string and an optional seed as an int, returns a 128 bit\n        // hash using the x64 flavor of MurmurHash3, as an unsigned hex.\n        //\n        if (library.inputValidation && !_validBytes(bytes)) {\n            return undefined;\n        }\n        seed = seed || 0;\n\n        var remainder = bytes.length % 16;\n        var blocks = bytes.length - remainder;\n\n        var h1 = [0, seed];\n        var h2 = [0, seed];\n\n        var k1 = [0, 0];\n        var k2 = [0, 0];\n\n        var c1 = [0x87c37b91, 0x114253d5];\n        var c2 = [0x4cf5ad43, 0x2745937f];\n\n        for (var i = 0; i < blocks; i = i + 16) {\n            k1 = [(bytes[i + 4]) | (bytes[i + 5] << 8) | (bytes[i + 6] << 16) | (bytes[i + 7] << 24), (bytes[i]) |\n                (bytes[i + 1] << 8) | (bytes[i + 2] << 16) | (bytes[i + 3] << 24)];\n            k2 = [(bytes[i + 12]) | (bytes[i + 13] << 8) | (bytes[i + 14] << 16) | (bytes[i + 15] << 24), (bytes[i + 8]) |\n                (bytes[i + 9] << 8) | (bytes[i + 10] << 16) | (bytes[i + 11] << 24)];\n\n            k1 = _x64Multiply(k1, c1);\n            k1 = _x64Rotl(k1, 31);\n            k1 = _x64Multiply(k1, c2);\n            h1 = _x64Xor(h1, k1);\n\n            h1 = _x64Rotl(h1, 27);\n            h1 = _x64Add(h1, h2);\n            h1 = _x64Add(_x64Multiply(h1, [0, 5]), [0, 0x52dce729]);\n\n            k2 = _x64Multiply(k2, c2);\n            k2 = _x64Rotl(k2, 33);\n            k2 = _x64Multiply(k2, c1);\n            h2 = _x64Xor(h2, k2);\n\n            h2 = _x64Rotl(h2, 31);\n            h2 = _x64Add(h2, h1);\n            h2 = _x64Add(_x64Multiply(h2, [0, 5]), [0, 0x38495ab5]);\n        }\n\n        k1 = [0, 0];\n        k2 = [0, 0];\n\n        switch (remainder) {\n            case 15:\n                k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 14]], 48));\n\n            case 14:\n                k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 13]], 40));\n\n            case 13:\n                k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 12]], 32));\n\n            case 12:\n                k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 11]], 24));\n\n            case 11:\n                k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 10]], 16));\n\n            case 10:\n                k2 = _x64Xor(k2, _x64LeftShift([0, bytes[i + 9]], 8));\n\n            case 9:\n                k2 = _x64Xor(k2, [0, bytes[i + 8]]);\n                k2 = _x64Multiply(k2, c2);\n                k2 = _x64Rotl(k2, 33);\n                k2 = _x64Multiply(k2, c1);\n                h2 = _x64Xor(h2, k2);\n\n            case 8:\n                k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 7]], 56));\n\n            case 7:\n                k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 6]], 48));\n\n            case 6:\n                k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 5]], 40));\n\n            case 5:\n                k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 4]], 32));\n\n            case 4:\n                k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 3]], 24));\n\n            case 3:\n                k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 2]], 16));\n\n            case 2:\n                k1 = _x64Xor(k1, _x64LeftShift([0, bytes[i + 1]], 8));\n\n            case 1:\n                k1 = _x64Xor(k1, [0, bytes[i]]);\n                k1 = _x64Multiply(k1, c1);\n                k1 = _x64Rotl(k1, 31);\n                k1 = _x64Multiply(k1, c2);\n                h1 = _x64Xor(h1, k1);\n        }\n\n        h1 = _x64Xor(h1, [0, bytes.length]);\n        h2 = _x64Xor(h2, [0, bytes.length]);\n\n        h1 = _x64Add(h1, h2);\n        h2 = _x64Add(h2, h1);\n\n        h1 = _x64Fmix(h1);\n        h2 = _x64Fmix(h2);\n\n        h1 = _x64Add(h1, h2);\n        h2 = _x64Add(h2, h1);\n\n        return (\"00000000\" + (h1[0] >>> 0).toString(16)).slice(-8) + (\"00000000\" + (h1[1] >>> 0).toString(16)).slice(-8) + (\"00000000\" + (h2[0] >>> 0).toString(16)).slice(-8) + (\"00000000\" + (h2[1] >>> 0).toString(16)).slice(-8);\n    };\n\n    // INITIALIZATION\n    // --------------\n\n    // Export murmurHash3 for CommonJS, either as an AMD module or just as part\n    // of the global object.\n    if (typeof exports !== 'undefined') {\n\n        if (typeof module !== 'undefined' && module.exports) {\n            exports = module.exports = library;\n        }\n\n        exports.murmurHash3 = library;\n\n    } else if (typeof define === 'function' && define.amd) {\n\n        define([], function () {\n            return library;\n        });\n    } else {\n\n        // Use murmurHash3.noConflict to restore `murmurHash3` back to its\n        // original value. Returns a reference to the library object, to allow\n        // it to be used under a different name.\n        library._murmurHash3 = root.murmurHash3;\n\n        library.noConflict = function () {\n            root.murmurHash3 = library._murmurHash3;\n            library._murmurHash3 = undefined;\n            library.noConflict = undefined;\n\n            return library;\n        };\n\n        root.murmurHash3 = library;\n    }\n})(this);\n"]},"metadata":{},"sourceType":"script"}